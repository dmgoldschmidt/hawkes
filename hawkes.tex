\documentclass[12pt,leqno]{article}
\include{article_defs}
\title{A Primer on the Hawkes Process}
\author{David M. Goldschmidt}
%\oddsidemargin 10 pt \evensidemargin 10 pt \marginparwidth 0.75 in \textwidth
%6.0 true in \topmargin -40 pt \textheight 8.8 true in 
%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\lfoot{}
%\rfoot{\thepage}
\begin{document}
%\renewcommand{\footrulewidth}{0.4pt}
\newcommand{\p}{\ensuremath{u}}
\newcommand{\VV}{V}
\maketitle


\section{Introduction}
In this expository paper, we review the basics of the Hawkes process, step by step.

\section{The Exponential Probability Density}
The exponential density with rate $\lambda$ is defined on the non-negative real line and has the probability
density function
\begin{equation}
  f_{\lambda}(t) := {\lambda}e^{-\lambda{t}}.
\end{equation}
The reason the parameter $\lambda$ is called the {\em rate} is that the expected value of $f_{\lambda}$ can be found by
integrating by parts:
\begin{align*}
E_{\lambda} &= \lambda\left(\int_0^{\infty}te^{-\lambda{t}}dt\right) = \lambda\left(\lambda^{-1}{t}e^{-\lambda{t}}\biggr\rvert_0^{\infty}
-\lambda^{-1}\int_0^{\infty}e^{-\lambda{t}}dt\right)\\
&= \lambda(\lambda^{-2}) = \lambda^{-1}.
\end{align*}
So if a sequence of events is arriving with the {\em inter-arrival time} $\tau$ between successive events
distributed as $f_{\lambda}(\tau)$, then the expected value of $\tau$ is $\lambda^{-1}$ units of time per
event, which means that the mean rate of arrivals is $\lambda$ events per unit of time.

We can sample from this density as follows.  Let
\begin{equation} \label{y=F(t)}
y = F_{\lambda}(t) := \int_0^{t}f_{\lambda}(\tau)d\tau = -e^{-\lambda\tau}\biggr\rvert_0^t = 1 - e^{-\lambda{t}}
\end{equation}
be the cumulative distribution function of $f_{\lambda}$. Then $y$ is a random variable on $[0,1]$ which we claim
is uniformly distributed.  Namely, let $y_0 = F_{\lambda}(t_0)$, then the probability that $y$ lies between $y_0$ and
$y_0+dy$ is the same as the probability that $t$ lies between $t_0$ and $t_0+dt$, which is the area of the
infinitesmal rectangle $f_{\lambda}(t_0)dt$  under $f_{\lambda}(t)$.  Since $dy = F'_{\lambda}(t)dt = f_{\lambda}(t)dt$,
we conclude that $y$ is uniformly distributed as claimed.\footnote{This argument is completely general.  It has nothing to do with the details of the density $f_{\lambda}$.}

Now from \eqref{y=F(t)} we obtain
\begin{equation}\label{t=Finv(y)}
  e^{-\lambda{t}} = 1 -y,\quad\text{hence}\quad t = -\frac{\log(1-y)}{\lambda}.
\end{equation}
Thus, to sample $t$ according to the density $f_{\lambda}(t)$, we first sample $y$ uniformly and then apply
\eqref{t=Finv(y)}.

\section{The EM algorithm}
In this section we review the application of EM algorithm to mixture densities.

\subsection{The Q-function}\label{Qf} 
\begin{Lem}\label{Qfunct} Suppose that $f_1(x),\dots,f_n(x)$ are positive real-valued functions.
Let $f(x):= \sum_{i=1}^nf_i(x)$, and define 
$$
Q(x',x):= \sum_{i=1}^nf_i(x')\log(f_i(x)).
$$
Then $ f(x) - f(x') \ge Q(x',x) - Q(x',x')$ with equality only if
$Q(x',x) = Q(x',x')$.
\end{Lem}
\begin{proof}
The equation of the tangent line to the graph of $y = \log(x)$ at $x = 1$ is $y = x - 1$.
Since $\log(x)$ is concave down, it follows that 
$\log(x) \le x - 1$, with equality if and only if $x = 1$. Using this, we have
\begin{align*}
Q(x',x) - Q(x',x') &= \sum_{i=1}^nf_i(x')[\log(f_i(x) - \log(f_i(x'))] \\
&= \sum_{i=1}^nf_i(x')\log(f_i(x)/f_i(x')) \\
&\le \sum_{i=1}^nf_i(x')[f_i(x)/f_i(x') - 1] \\
&= \sum_{i=1}^n[f_i(x) - f_i(x')] \\
&= f(x) - f(x'),
\end{align*}
with equality if and only if $f_i(x)/f_i(x') = 1$ for all $i$.
\end{proof}

Of course, the point is that it is often possible to write a (log-)likelihood
function $L(\theta)$ as a sum $L(\theta) = \sum_iL_i(\theta)$ where $L_i(\theta)$ has
a relatively simple form. Then given a set of parameters $\theta'$, we can find a
more likely set $\theta$ by choosing $\theta$ so that $Q(\theta',\theta) >
Q(\theta',\theta')$.  In practice, we usually maximize $Q(\theta',\theta)$ as a function of
$\theta$.  We can then replace $\theta'$ by $\theta$ and iterate until a {\em
  local} maximum of $L(\theta)$ is reached.    This iteration is referred to in the literature
as the EM algorithm.

\subsection{Mixture Densities}\label{MD}
A standard application of the $Q$-function technology is to the maximum
likelihood problem for a mixture density.  Here we have a set of
probability densities $p_1(\eta;y),\dots,p_s(\eta;y)$ where $\eta$
denotes a set of parameters and $y$ is an observation.  The yoga is that there
is a "hidden state" $i\in\{1,2,\dots,s\}$ such that $p_i(\eta;y)$ is the
conditional probability density of $y$ given parameters $\eta$ and state $i$.

Given a vector $\omega:= \{\omega_1,\dots,\omega_n\}$ of state probabilities, we put
$\theta:= (\eta,\omega)$.  The mixture density is then
$$
p(\theta;y) = \sum_{i=1}^s\omega_ip_i(\eta;y).
$$

Now suppose we are given a sequence $\{y_1,\dots,y_N\}$ of observations which we
assume are i.i.d. samples from this density,
and we want choose parameters $\theta$ to maximize the likelihood of the observations.
The likelihood function is  
\begin{equation*} \begin{split} 
L(\theta)
&:= \prod_{n=1}^N\sum_{i=1}^s\omega_ip_i(\eta,y_n) \\ 
&=
\sum_{i_1,\dots,i_N=1}^s\prod_{n=1}^N\omega_{i_n}p_{i_n}(\eta,y_n), \\ 
\end{split} 
\end{equation*} 
and the $Q$-function for this sum is 
$$
Q(\theta',\theta) = \sum_{i_1,\dots,i_N=1}^s\prod_{n=1}^N\omega'_{i_n}p_{i_n}(\eta';y_n)
\sum_{k=1}^N\log(\omega_{i_k}p_{i_k}(\eta;y_k)).
$$
The good news here is that there is a significant simplification of this expression.
Namely, the coefficient of $\log(\omega_mp_m(\eta;y_n))$ in the above sum is given by
\begin{align*}
\omega'_mp_m(\eta';y_n)\sum_{I:i_n = m}\prod_{j\neq n}\omega'_{i_j}p_{i_j}(\eta';y_j )
&=\omega'_mp_m(\eta';y_n)\prod_{j\neq n}\sum_{i=1}^s\omega'_ip_i(\eta';y_j)\\
&= \frac{\omega'_mp_m(\eta';y_n)}{p(\theta';y_n)}\prod_{j=1}^Np(\theta';y_j).
\end{align*}
Note that the quantity 
\begin{equation}\label{omega_mn}
\omega'_{mn} := \frac{\omega'_mp_m(\eta';y_n)}{p(\theta';y_n)}
\end{equation}
is the conditional probability of state $m$ at observation time $n$, given observation $y_n$ 
and parameters $\eta'$.
Thus, dividing by the constant $\prod_jp(\theta',y_j)$ and changing notation, the function to be
maximized is
\begin{equation}\label{Qfunc:0}
\tilde{Q}(\theta',\theta) := \sum_{m=1}^s\sum_{n=1}^N\omega'_{mn}\log(\omega_mp_m(\eta;y_n)),
\end{equation}
where, as above, $\omega'$ denotes the prior value, while $\omega$ and $\eta$ are the unknown parameters
to be solved for which will maximize $\tilde{Q}$.

\section{Nonlinear Least Squares}\label{NLS}
Here we are given a differentiable function $f(X)$ of a vector variable
$X = (x_1,\dots,x_n)$ and a set of observations $\{X_i,y_i \mid 1\le i\le m\}$ where typically $m >> n$
together with an initial guess $\hat{X}$ for $X$.  We would like to ``solve'' the overdetermined system of
non-linear equations $y_i = f(X_i)$ by minimizing the sum of squares of the residuals
$$
S := \sum_{i=1}^m (f(X_i)-y_i)^2.
$$

We first compute
$$
a_{ij} := \frac{\partial{f}}{\partial{x_j}}(\hat{X}_i),\quad\text{and}\quad b_i := y_i - f(\hat{X}_i).
$$
We then apply the first-order Taylor expansion of $f$ at $\hat{X}$ to each observation:
$$
f(X_i) = f(\hat{X}_i) + \sum_{j=1}^na_{ij}(X - \hat{X}_i).
$$
obtaining an overdetermined linear system $A(X-\hat{X}) = b$, 
where
$$
A := [a_{ij}]\quad\text{and}\quad b := [b_i].
$$
This system has the solution
$$
X = \hat{X} + (A^tA)^{-1}A^tb.
$$

We can then replace our initial guess $\hat{X}$ by $X$, and iterate this procedure as required.

\section{The Homogeneous Poisson Process}
For our purposes, a Poisson process of rate $\lambda$ will be defined as an increasing sequence of random variables
$ \{0 < T_1 < T_2 < \dots\}$ defined on $(0,\infty)$ such that $\{\tau_i = T_i-T_{i-1}~|~ i = 1,2,\dots\}$ are i.i.d.
exponential of rate $\lambda$. We often think of $T_i$ as the time of occurence of the $i^{th}$
event, where often the event is the arrival of something.  So in the following, we will call the $T_i$
``arrival times'' and the $\tau_i$ ``inter-arrival times''.  

The quantity of interest here
is $Pd(T_n = t)$, the probability density that the $n^{th}$ arrival occurs at time $t$.
\begin{Thm}
  Let $\{0 < T_1<\dots<T_n<... \}$ be a Poisson process of rate $\lambda$.  Then
  \begin{equation}\label{erlang}
  Pd(T_n = t) = \frac{\lambda^nt^{n-1}}{(n-1)!}e^{-\lambda{t}}.
  \end{equation}
  \begin{proof}
    Put $\tau_i = t_i - t_{i-1}$ for all $i$ as above. Then the $\tau_i$ are i.i.d. exponential of rate $\lambda$, and
    $t_j = \sum_{i=1}^j \tau_i$ for all $j$.  In particular $t_1 = \tau_1$ so the theorem is trivial for $n = 1$.
    Inductively, assume that it holds for $n-1$. Then $t = t_{n-1} + \tau_n$ is the sum of two independent random
    variables and hence $Pd(T_n = t)$ is the convolution
    \begin{align*}
      Pd(T_n = t) &= Pd(T_{n-1} = s)*({\lambda}e^{-\lambda(t-s)})\\
      &= \lambda\int_{s=0}^t\frac{\lambda^{n-1}s^{n-2}}{(n-2)!}e^{-\lambda{s}}{\lambda}e^{-\lambda(t-s)}ds \\
      &= \frac{\lambda^n}{(n-2)!)}e^{-\lambda{t}}\int_{s=0}^ts^{n-2}ds \\
      &= \frac{\lambda^nt^{n-1}}{(n-1)!}e^{-\lambda{t}}.
    \end{align*}
  \end{proof}
\end{Thm}
The probability density \eqref{erlang} is known as the gamma density in the literature.

Now define $\nu(t)$ to be the ``counting function'' which is the total number of arrivals up to time $t$.
\begin{Cor}
  For a Poisson process of rate $\lambda$ as in the theorem, 
  \begin{equation}\label{poisson}
  Pr(\nu(t) = n) = \frac{\lambda^nt^{n}}{n!}e^{-\lambda{t}}.
  \end{equation}
  \begin{proof}
    For $n = 0$, the event $\nu(t) = 0$ is just the event $T_1 > t$, hence
    $$
    Pr(\nu(t) = 0) = \int_t^{\infty}Pd(T_1 = s)ds = \int_t^{\infty}{\lambda}e^-{\lambda{s}}ds = e^{-\lambda{t}}.
    $$
    Now for $n > 0$, we have
    \begin{align*}
      Pr(\nu(t) = n) &= \int_0^tPd(T_n = s \& \nu(t-s) = 0)\\
      &= \int_0^t\frac{\lambda^ns^{n-1}}{(n-1)!}e^{-\lambda{s}}e^{-lambda(t-s)}ds\\
      &=\frac{\lambda^n}{(n-1)!}e^{-\lambda{t}}\int_0^t s^{n-1}ds\\
      &= \frac{\lambda^nt^{n}}{n!}e^{-\lambda{t}}.
    \end{align*}
  \end{proof}
\end{Cor}
The probability distribution \eqref{poisson} is known in the literature as the poisson distribution.

\begin{Cor}
  For a Poisson process of rate $\lambda$ as in the theorem, 
  the expected number of arrivals up to time $t$ is $\lambda{t}$.
  \begin{proof}
    \begin{align*}
      \sum_{n=0}^{\infty}nPr(\nu(t) = n) &= \lambda{t}e^{-\lambda{t}}\sum_{n=1}^{\infty}\frac{(\lambda{t})^{n-1}}{(n-1)!}\\
      &=\lambda{t}e^{-\lambda{t}}e^{\lambda{t}}\\
      &= \lambda{t}.
    \end{align*}
  \end{proof}
\end{Cor}
        
   
\section{The Inhomogeneous Poisson Process}
We next consider a generalization of the Poisson process in which we allow the rate $\lambda$ to vary with time.
Among the infinitely many ways this might be done, we will consider here only a simple exponential decay model:
\begin{equation}\label{exp_rate}
  \lambda(t) := {\sigma}e^{-\rho{t}}
\end{equation}
where $\sigma$ and $\rho$ are non-negative decay parameters.
Then the expected number of arrivals in the interval $[t_0,t_1]$ is
\begin{equation}\label{k_hat}
  \hat{k}(t_0,t_1) := \int_{t_0}^{t_1}\lambda(t)dt = \frac{\sigma}{\rho}(e^{-\rho{t_0}}- e^{-\rho{t_1}}),
\end{equation}
and the mean rate in that interval is
\begin{equation}\label{lambda_hat}
  \hat{\lambda}(t_0,t_1) := \frac{\hat{n}(t_0,t_1)}{t_1 - t_0}.
\end{equation}

In the sequel, we will approximate an inhomogenous Poisson process with exponentially decaying rate $\lambda(t)$
in an interval $[t_0,t_1]$ by the homogeneous Poisson process with rate $\hat{\lambda}(t_0,t_1)$.  In particular,
\eqref{erlang} becomes
\begin{equation}\label{erlang:1}
  Pd(T_n = t) = \frac{\hat{\lambda}(0,t)^nt^{n-1}}{(n-1)!}e^{-t\hat{\lambda}(0,t)},
\end{equation}
and if $n$ is a random variable whose distribution is known but whose value is unknown, we will further approximate
\eqref{erlang} by substituting $\hat{n}(0,t)$ for $n$ in \eqref{erlang:1}.


\section{The Hawkes Process}
\subsection{A branching Poisson process}
We now introduce dependencies among the arrival times $T_i$, by allowing each arrival event 
to spawn a new Poisson process, which we call a child process as opposed to the original process which we
call the base process.  This leads to a view of the Hawkes process as a branching Poisson process. There
is another view of the Hawkes process as an inhomogeneous Poisson process whose intensity changes by positive
jumps at each arrival time.  The two views are mathematically equivalent, but we will take the branching view here.

An important difference between the base process and all the child processes is that the base process
has a constant rate $\lambda_0$ \footnote{This can be generalized to a time-dependent rate, but it is usually not exponentially decaying.} while the child processes all have exponentially decaying rates.  We denote the base
process by $\P_0$ and the child process spawned at arrival time
$t_j~(j > 0)$ by $\P_j$.  

We will make one further generalization, namely we may see
different types of events.  Event types are often called ``marks'' in the literature, and a process with different
event types is called a ``marked process''. 
Then our observations are pairs $(t,m)$ meaning that an event of type $m$ has occured at time $t$.  In this
case we denote the mark of event $i$ by $\mu(i)$ for $i > 0$, and we allow the exponential decay parameters for
child process
$\P_j$ to depend on $\mu(j)$, the mark of the originating event at arrival time $t_j$.  Then for
$j>0$, $\P_j$ has rate
\begin{equation}\label{child_rate}
\lambda_j(t) =
\begin{cases}
  \sigma_{m}e^{-\rho_{m}(t-t_j)}\quad\text{for $m = \mu(j)$ and $t > t_j$}\\
  0\quad\text{for $t \le t_j$}.
\end{cases}
\end{equation}
For $0 < j < i$, We define
\begin{align*}
  t_{ij} :&= t_i-t_j,\\
  \lambda_{ij} :&= \hat{\lambda}_j(t_j,t_i),\quad\text{and}\\
  \k_{ij} :&= \frac{\lambda_{ij}}{t_{ij}}.
\end{align*}

So $\lambda_{ij}$ is the mean rate of process $\P_j$ over
the interval $[t_j,t_i]$, as given by \eqref{lambda_hat}.\footnote{$\lambda_{ij}$ depends on decay
  parameters $\sigma$ and $\rho$ which we will specify below.} and $\k_{ij}$ is the expected number
of arrivals from $\P_j$ up to time $t_i$.  In particular, we have
  $\lambda_{i0} := \lambda_0$ for all $i$ because the base process is homogeneous.
  
\subsection{The Model}
We want to explain an observed arrival stream $\{(t_1,\mu(1),\dots,(t_N,\mu(N)\}$ as the output
of a Hawkes process.  All arrival times are given as elapsed times from some reference time $t_0$,
which we take to be the starting time of the base process.  Thus, $t_1$ is the arrival time of the first
base process event, and $t_{i0}$ is just $t_i$.

If $t_i$ is the arrival time of an event generated by process $\P_j$ for some index $j < i$, and
if $\P_j$ has generated $k_{ij}-1$ previous events prior to time $t_i$, then 

\begin{equation}\label{p_ij}
  p_{ij} :=  Pd(T_i = t_i \mid j, k_{ij}) = \frac{\lambda_{ij}^{k_{ij}}t_{ij}^{(k_{ij}-1)}}{(k_{ij}-1)!}e^{-\lambda_{ij}t_{ij}}
\end{equation}
by \eqref{erlang}, where $\lambda_{ij}$ and $t_{ij}$ were defined above.

Unfortunately, however, neither the value of $k_{ij}$ nor even the value of $j$ is  observed, i.e. we don't know
which process $\P_j$ generated the event $T_i = t_i$, nor do we know how many events were generated by $\P_j$
prior to $t_i$.  Thus, we can't use \eqref{erlang} directly. Instead,
we define a hidden state space $S := \{0,1,2,\dots,N\}$ and assume that $j\in{S}$ has probability $Pr(j) := \omega_j$.
This makes $j$ a random variable with a prior distribution and converts \eqref{p_ij} to a mixture distribution, but
we still don't know the value of $k_{ij}$.  So we
will replace $k_{ij}$ by its expected value $\k_{ij}$, the expected number of events generated by $\P_j$
in the interval $(t_j,t_i]$, which is  given by \eqref{k_hat}, which also shows that $\lambda_{ij} = \k_{ij}t_{ij}^{-1}$
Thus, making all these substitutions into \eqref{p_ij} we get
\begin{equation}\label{q_ij}
  \begin{split}
    q_{ij} :&= \frac{(\k_{ij}t_{ij}^{-1})^{\k_{ij}}t_{ij}^{(\k_{ij}-1)}}{\Gamma(\k_{ij})}e^{-\k_{ij}}\quad (j < i)\\
    &= \frac{\k_{ij}^{\k_{ij}}t_{ij}^{-1}}{\Gamma(\k_{ij})}e^{-\k_{ij}}.
  \end{split}
\end{equation}

Then our likelihood function becomes a product of mixture distributions, as discussed in section \eqref{MD}:
$$
L = \prod_{i=1}^NPd(T_i = t_i)
$$
where 
\begin{equation}\label{likelihood}
    Pd(T_i = t_i) = \sum_{j=0}^{i-1}\omega_jq_{ij}.
\end{equation}

At first glance, it appears that we might have a large number of states.  However, note first that $q_{ij} = 0$ for $j \ge i$, and second that $q_{ij}$ decays exponentially in $t_i-t_j$, so in practice we can ignore states $j << i$.


\subsection{Optimizing the Parameters}
In this section we use the EM algorithm to optimize the model parameters.
Given the data $\{(t_1,\mu(t_i),\dots(t_N,\mu(t_N)\}$, we let $M$ denote the set of distinct marks $\mu(t_i)$
seen in the data.  Our model parameters are
$$
\theta := \lambda_0, \{\sigma_m, \rho_m, \mid m \in M\},~\text{and}~ \{\omega_j\mid 0\le j\le N\},
$$
and the Q-function to be maximized (see \eqref{Qfunc:0}) becomes
\begin{equation}\label{Q}
\tilde{Q}(\theta) = \sum_{i=1}^N\sum_{j=0}^{i-1}\omega_{ij}'\log(\omega_jq_{ij}),
\end{equation}
where, following \eqref{omega_mn}, $\omega'_{ij}$ is the (prior) conditional
probability of the event $T_i=t_i$,
given that it was generated by process $\P_j$.  We compute $\omega'_{ij}$ by
treating the density $\omega'_jq'_{ij}$ as the likelihood of the event $T_i = t_i$ given state $j$,
and normalizing to a distribution:
\begin{equation}\label{omega'_ij}
\omega'_{ij} :=
\begin{cases}
  \frac{\omega'_jq'_{ij}}{\sum_j\omega'_jq'_{ij}}&(j < i) \\
  0&(j \ge i).
\end{cases}
\end{equation}


We can now maximize $\tilde{Q}(\theta)$ by setting partial derivatives with respect to $\theta$ to
zero and solving the resulting equations for the posterior parameters.  We first solve for $\omega_j$, keeping in
mind the constraint
$$
\sum_{j=0}^N\omega_j = 1,
$$
which we will enforce using a Lagrange multiplier $\eta$ as follows:

\begin{align*}
  0 &= \frac{\partial}{\partial\omega_j}\left(\tilde{Q} + \eta(1-\sum_{j=0}^N\omega_j )\right) \\
  &= \frac{1}\omega_j\sum_{i=1}^N\omega_{ij}' - \eta.
\end{align*}
We conclude that
\begin{equation}\label{omega_j:0}
  \begin{split}
  \eta\omega_j &= \sum_{i=1}^N\omega_{ij}',\quad\text{whence} \\
  \eta\sum_{j=0}^N\omega_j &= \sum_{i=1}^N\sum_{j=0}^N\omega'_{ij}.
  \end{split}
\end{equation}
Since
$$
\sum_{j=0}^N \omega_j = 1 = \sum_{j=0}^N\omega'_{ij},
$$
it follows that $\eta = N$ and thus \eqref{omega_j:0} yields
\begin{equation}\label{omega_j}
  \omega_j = \frac{1}{N}\sum_{i=1}^N\omega'_{ij}.
\end{equation}

To solve for the remaining parameters, we first expand \eqref{Q}:
\begin{equation}\label{Q1}
  \begin{split}
    \tilde{Q} &= \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}\log\left(\omega_j\frac{\k_{ij}^{\k_{ij}}t_{ij}^{-1}}
          {\Gamma(\k_{ij})}e^{-k_{ij}} \right)\\
    &= \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}\left(\log(\omega_j)+\k_{ij}(\log(\k_{ij}) - \log(t_{ij})) 
          -\log(\Gamma(\k_{ij})) -\k_{ij}\right)\\
  \end{split}
\end{equation}
Note that \eqref{Q1} can be considerably simplified by using Stirling's approximation:
\begin{equation}\label{stirling}
  \log(\Gamma(x)) =  (x\log(x) -x - .5\log(x) + .5\log(2\pi) + O\left(\frac{1}{12(x+1)})\right).% + O\left(\frac{1}{12(x+1)(x+2)}.
\end{equation}
Substituting this approximation into \eqref{Q1} yields
\begin{equation}\label{Q2}
  \begin{split}
    \tilde{Q} &\approx \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}(\log(\omega_j)+\k_{ij}\log(\k_{ij}) - \log(t_{ij})
    -(\k_{ij}\log(\k_{ij}) -\k_{ij} -.5\log(\k_{ij}) \\
    &+ .5\log(2\pi)) -\k_{ij})\\
  &= \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}\left(\log(\omega_j) - \log(t_{ij}) + .5\log(\k_{ij})
  - .5\log(2\pi) \right),
  \end{split}
\end{equation}
and hence
\begin{equation}\label{dQ_dk}
  \frac{\partial\tilde{Q}}{\partial\k_{ij}} = \frac{\omega'_{ij}}{2\k_{ij}}.
\end{equation}


We can now solve for $\k_{ij}$.  We will enforce a constraint, namely that
the total number of expected arrivals at time $t_l$ equals the actual number, which is just $l$:
$$
\sum_{m=0}^{l-1}\k_{lm} = l.
$$
Put
$$
\Sigma_l:= l - \sum_{m=0}^{l-1}\k_{lm} \quad(1\le l \le N).
$$
Note that
$$
\frac{\partial\Sigma_l}{\partial\k_{ij}} = \delta_{li}\begin{cases}
  1 & \text{if $j < i$ } \\
  0 & \text{if $j \ge i$}.
\end{cases}
$$
Once again, we enforce the constraints $\Sigma_l = 0$  using lagrange multipliers $\eta_l$ for $(1\le l\le N)$:
\begin{equation}
  \begin{split}
    0 &= \frac{\partial\tilde{Q}}{\partial\k_{ij}} + \sum_{l=1}^N\eta_l\frac{\partial\Sigma_l}{\partial\k_{ij}} \\
    &= \frac{\omega'_{ij}}{2\k_{ij}} - \eta_i,\quad\text{whence}\\
    2\k_{ij}  &= \omega'_{ij}\eta_i^{-1},\\
    2\sum_{j=0}^{i-1}\k_{ij} &= \eta_i^{-1}\sum_{j=0}^{i-1}\omega'_{ij},\\
    \eta_i &= \frac{1}{2i}\sum_{j=0}^{i-1}\omega'_{ij},\\
  \end{split}
\end{equation}
However, by definition (see \eqref{omega'_ij}) we have
$$
\sum_{j=0}^{i-1}\omega'_{ij} = 1\quad\text{for all $i,j$},
$$
so therefore we get
\begin{equation}\label{k_hat:1}
  \k_{ij} = i\omega'_{ij}.
\end{equation}

In particular, we can solve for $\lambda_0$ since $\k_{i0} = \lambda_0t_i$, and from \eqref{k_hat:1}
we get
\begin{equation}\label{lambda_0}
  \begin{split}
\lambda_0 &= \omega'_{i0}\frac{i}{t_i} \quad\text{for all $i$, and summing over $i$ we have}\\
\lambda_0 &= \frac{1}{N}\sum_{i=1}^N\omega'_{i0}\frac{i}{t_i}.
  \end{split}
\end{equation}

To solve for the remaining decay parameters $\sigma_m$ and $\rho_m$, 
we let $J(m)$ be the set of indices $j$ such that $\mu(j) = m$:
$$
J(m) := \{j\in 0,1,\dots,N \mid \mu(j) = m\}.
$$

To review, recall from \eqref{lambda_hat}, \eqref{k_hat}, and \eqref{child_rate} that $\tilde{Q}$ depends on
$\sigma_m$ and $\rho_m$ only through $\lambda_{ij}$ and $\k_{ij}$, namely for $j\in J(m)$ we have:
\begin{equation}\label{k_ij}
\k_{ij} = \k(t_j,t_i) = \frac{\sigma_m}{\rho_m}(e^{-\rho_m{t_j}}- e^{-\rho_m{t_i}}).
\end{equation}

Having already solved for $\k_{ij}$, \eqref{k_ij} provides many equations to solve for $\sigma_m$ and $\rho_m$.
We will use non-linear least squares, as discussed in section \ref{NLS}.

So we first compute, for $j\in J(m)$ and all $i$,
\begin{equation}\label{d_sigma,rho}
  \begin{split}
    \frac{\partial\k_{ij}}{\partial\sigma_m} &= \frac{1}{\rho_m}(e^{-\rho_m{t_j}}- e^{-\rho_m{t_i}}) = \frac{\k_{ij}}{\sigma},\\
 \frac{\partial\k_{ij}}{\partial\rho_m} &= -\frac{1}{\rho_m}\k_{ij}+\frac{\sigma_m}{\rho_m}(t_ie^{-\rho_mt_i}-t_je^{-\rho_mt_j}).
  \end{split}
\end{equation}

We then evaluate \eqref{k_ij} and \eqref{d_sigma,rho} at the prior parameters $\sigma'_m,~\rho'_m$, to obtain
overdetermined linear equations in $\Delta\sigma_m$ and $\Delta\rho_m$ as in section \eqref{NLS} which we use
to reestimate $\sigma_m$ and $\rho_m$.  We can then choose to iterate by recomputing partials, or just proceed
with another EM iteration.

\section{Numerical Results}
\end{document}


The probability density of any finite set of arrival times
$S_n = \{T_1 = t_1 < T_2 = t_2<\dots<T_n = t_n\}$ is easy to compute. Using independence we see that
\begin{equation}\label{arr_seq}
Pd(S_n) = \prod_{i=1}^n\lambda{e}^{-\lambda(t_i - t_{i-1})} = \lambda^ne^{-\lambda\sum_{i = 1}^n(t_i-t_{i-1})} = \lambda^ne^{-\lambda{t_n}}.
\end{equation}
In particular, the density of any particular arrival sequence does not depend on the intermediate arrival times
at all, only on the number of arrivals and the time of the last arrival.

We then apply \eqref{Q1} for all $i$ and $j>0$ to obtain 
\begin{equation}\label{dQ_dlambda,k}
   \begin{split}
     \frac{\partial\tilde{Q}}{\lambda_{ij}} &= \omega'_{ij}\left(\k_{ij}\lambda_{ij}^{-1}-t_{ij}\right), \\
    \frac{\partial\tilde{Q}}{\k_{ij}} &= \omega'_{ij}(\log(\lambda_{ij}t_{ij})-\psi(\k_{ij})).
   \end{split}
\end{equation}

Finally, for $x = \sigma_m$ and $x = \rho_m$, we have the chain rule:
\begin{equation}\label{dQ_dsigma,rho}
  0 = \frac{\partial\tilde{Q}}{\partial{x}} = \sum_{i=1}^N\sum_{j\in J(m)}\frac{\partial\tilde{Q}}{\partial\lambda_{ij}}\frac{\partial\lambda_{ij}}{\partial{x}} +
    \frac{\partial\tilde{Q}}{\partial\k_{ij}}\frac{\partial\k_{ij}}{\partial{x}}.
\end{equation}

By substituting \eqref{dQ_dlambda,k} and \eqref{d_dsigma,rho} into \eqref{dQ_dsigma,rho},
we can solve numerically for $\sigma_m$ and $\rho_m$.




Next, we recall Horner's rule for polynomial evaluation, namely for any positive integer $m$ and any
real number $x$, we define
$$
f_0(m,x) = 1\quad\text{and}\quad f_{k+1}(m,x) = 1+\frac{x}{m-k}f_k(m,x)\quad(0\le k\le m-1).
$$
Then
$$
f_m(m,x) = \sum_{k=0}^m\frac{x^k}{k!}.
$$
Horner's rule is easy to verify by induction, and is more efficient and more numerically stable than the
naive algorithm.

For the base process ${\cal P}_0$, we have
\begin{align*}
  D_{i0} := \frac{\partial{q_{i0}}}{\partial\lambda_0} &= \frac{\partial}{\partial\lambda_0}\left(\lambda_0e^{-t_i(1-\delta_{00})\lambda_0}\sum_{k=1}^i\frac{(\lambda_0t_i)^k}{k!}\right)\\
  &= e^{-t_i(1-\delta_{00})\lambda_0}\sum_{k=1}^i\frac{(\lambda_0t_i)^k}{k!}\\
  &-\lambda_0t_i(1-\delta_{00})e^{-t_i(1-\delta_{00})\lambda_0}\sum_{k=1}^i\frac{(\lambda_0t_i)^k}{k!}\\
  &+\lambda_0e^{-t_i(1-\delta_{00})\lambda_0}\sum_{k=1}^i\frac{\lambda_0^{k-1}t_i^k}{(k-1)!}.
\end{align*}
   
To solve for the remaining parameters, we need some intermediate derivatives:
\begin{equation}\label{D_ij}
  \begin{split}
    D_{ij} := \frac{\partial{q_{ij}}}{\partial\lambda_{ij}} &= \frac{\partial}{\partial\lambda_{ij}}\left(\omega_j\frac{\lambda_{ij}^{\k_{ij}}t_{ij}^{(\k_{ij}-1)}}{\Gamma(\k_{ij})}e^{-\lambda_{ij}t_{ij}} \right)\\
    &= \omega_j\frac{t_{ij}^{(\k_{ij}-1)}e^{-\lambda_{ij}t_{ij}}}{\Gamma(\k_{ij})}\left(\k_{ij}\lambda_{ij}^{\k_{ij}-1} - t_{ij}\right)\\
  \end{split}
\end{equation}

\frac{\partial}{\partial\lambda_0}\sum_{i=1}^N\omega'_{i0}\log\left(\omega_0\frac{\lambda_0^{\lambda_0t_0}t_0^{(\lambda_0t_0-1)}}{\Gamma(\lambda_0t_0)}e^{-\lambda_0t_0} \right)\\
  &= \frac{\partial}{\partial\lambda_0}
  \sum_{i=1}^N\omega'_{i0}\left(\log(\omega_0)+\lambda_0t_0\log(\lambda_0)+(\lambda_0t_0-1)\log(t_0)
  -\log(\Gamma(\lambda_0t_0)) -\lambda_0t_0\right)\\

  We next solve for $\lambda_0$, first recalling that $\lambda_{i0} = \lambda_0$, $\k_{i0} = \lambda_0t_0$,
and that $q_{ij}$ does not depend on $\lambda_0$ for $j > 0$.  Then substituting these values into \eqref{Q1}
and deleting terms that don't depend on $\lambda_0$, we have:
\begin{equation}\label{lambda_0}
  \begin{split}
  0 &= \frac{\partial\tilde{Q}}{\lambda_0} = \frac{\partial}{\partial\lambda_0}\sum_{i=1}^N\omega'_{i0}\left(\lambda_0t_0\log(\lambda_0t_0)+(\lambda_0t_0-1)
  \log(t_0)-\log(\Gamma(\lambda_0t_0) - \lambda_ot_0\right)\\
  &= \sum_{i=1}^N\omega'_{i0}\left(t_0(\log(\lambda_0t_0)+1)+ t_0\log(t_0)-t_0\frac{\Gamma'(\lambda_0t_0)}{\Gamma(\lambda_0t_0)}-t_0\right)\\
  &=  \sum_{i=1}^N\omega'_{i0}\left( t_0(\log(\lambda_0) +2t_0\log(t_0)  -\psi(\lambda_0t_0)\right).
  \end{split}
\end{equation}
   where $\psi(x) := \frac{\Gamma'(x)}{\Gamma(x)}$ is the digamma function. We can solve \eqref{lambda_0} for
$\lambda_0$ numerically (e.g. using Newton's method) since standard numerical approximations exist for $\psi(x)$
and $\psi'(x)$.
