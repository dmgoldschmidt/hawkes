\documentclass[12pt,leqno]{article}
\include{article_defs}
\title{A Primer on the Hawkes Process}
\author{David M. Goldschmidt}
%\oddsidemargin 10 pt \evensidemargin 10 pt \marginparwidth 0.75 in \textwidth
%6.0 true in \topmargin -40 pt \textheight 8.8 true in 
%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\lfoot{}
%\rfoot{\thepage}
\begin{document}
%\renewcommand{\footrulewidth}{0.4pt}
\newcommand{\p}{\ensuremath{u}}
\newcommand{\VV}{V}
\maketitle


\section{Introduction}
In this expository paper, we review the basics of the Hawkes process, step by step.

\section{The Exponential Probability Density}
The exponential density with rate $\lambda$ is defined on the non-negative real line and has the probability
density function
\begin{equation}
  f_{\lambda}(t) := {\lambda}e^{-\lambda{t}}.
\end{equation}
The reason the parameter $\lambda$ is called the {\em rate} is that the expected value of $f_{\lambda}$ can be found by
integrating by parts:
\begin{align*}
E_{\lambda} &= \lambda\left(\int_0^{\infty}te^{-\lambda{t}}dt\right) = \lambda\left(\lambda^{-1}{t}e^{-\lambda{t}}\biggr\rvert_0^{\infty}
-\lambda^{-1}\int_0^{\infty}e^{-\lambda{t}}dt\right)\\
&= \lambda(\lambda^{-2}) = \lambda^{-1}.
\end{align*}
So if a sequence of events is arriving with the {\em inter-arrival time} $\tau$ between successive events
distributed as $f_{\lambda}(\tau)$, then the expected value of $\tau$ is $\lambda^{-1}$ units of time per
event, which means that the mean rate of arrivals is $\lambda$ events per unit of time.

We can sample from this density as follows.  Let
\begin{equation} \label{y=F(t)}
y = F_{\lambda}(t) := \int_0^{t}f_{\lambda}(\tau)d\tau = -e^{-\lambda\tau}\biggr\rvert_0^t = 1 - e^{-\lambda{t}}
\end{equation}
be the cumulative distribution function of $f_{\lambda}$. Then $y$ is a random variable on $[0,1]$ which we claim
is uniformly distributed.  Namely, let $y_0 = F_{\lambda}(t_0)$, then the probability that $y$ lies between $y_0$ and
$y_0+dy$ is the same as the probability that $t$ lies between $t_0$ and $t_0+dt$, which is the area of the
infinitesmal rectangle $f_{\lambda}(t_0)dt$  under $f_{\lambda}(t)$.  Since $dy = F'_{\lambda}(t)dt = f_{\lambda}(t)dt$,
we conclude that $y$ is uniformly distributed as claimed.\footnote{This argument is completely general.  It has nothing to do with the details of the density $f_{\lambda}$.}

Now from \eqref{y=F(t)} we obtain
\begin{equation}\label{t=Finv(y)}
  e^{-\lambda{t}} = 1 -y,\quad\text{hence}\quad t = -\frac{\log(1-y)}{\lambda}.
\end{equation}
Thus, to sample $t$ according to the density $f_{\lambda}(t)$, we first sample $y$ uniformly and then apply
\eqref{t=Finv(y)}.

\section{The EM algorithm}
In this section we review the application of EM algorithm to mixture densities.

\subsection{The Q-function}\label{Qf} 
\begin{Lem}\label{Qfunct} Suppose that $f_1(x),\dots,f_n(x)$ are positive real-valued functions.
Let $f(x):= \sum_{i=1}^nf_i(x)$, and define 
$$
Q(x',x):= \sum_{i=1}^nf_i(x')\log(f_i(x)).
$$
Then $ f(x) - f(x') \ge Q(x',x) - Q(x',x')$ with equality only if
$Q(x',x) = Q(x',x')$.
\end{Lem}
\begin{proof}
The equation of the tangent line to the graph of $y = \log(x)$ at $x = 1$ is $y = x - 1$.
Since $\log(x)$ is concave down, it follows that 
$\log(x) \le x - 1$, with equality if and only if $x = 1$. Using this, we have
\begin{align*}
Q(x',x) - Q(x',x') &= \sum_{i=1}^nf_i(x')[\log(f_i(x) - \log(f_i(x'))] \\
&= \sum_{i=1}^nf_i(x')\log(f_i(x)/f_i(x')) \\
&\le \sum_{i=1}^nf_i(x')[f_i(x)/f_i(x') - 1] \\
&= \sum_{i=1}^n[f_i(x) - f_i(x')] \\
&= f(x) - f(x'),
\end{align*}
with equality if and only if $f_i(x)/f_i(x') = 1$ for all $i$.
\end{proof}

Of course, the point is that it is often possible to write a (log-)likelihood
function $L(\theta)$ as a sum $L(\theta) = \sum_iL_i(\theta)$ where $L_i(\theta)$ has
a relatively simple form. Then given a set of parameters $\theta'$, we can find a
more likely set $\theta$ by choosing $\theta$ so that $Q(\theta',\theta) >
Q(\theta',\theta')$.  In practice, we usually maximize $Q(\theta',\theta)$ as a function of
$\theta$.  We can then replace $\theta'$ by $\theta$ and iterate until a {\em
  local} maximum of $L(\theta)$ is reached.    This iteration is referred to in the literature
as the EM algorithm.

\subsection{Mixture Densities}\label{MD}
A standard application of the $Q$-function technology is to the maximum
likelihood problem for a mixture density.  Here we have a set of
probability densities $p_1(\eta;y),\dots,p_s(\eta;y)$ where $\eta$
denotes a set of parameters and $y$ is an observation.  The yoga is that there
is a "hidden state" $i\in\{1,2,\dots,s\}$ such that $p_i(\eta;y)$ is the
conditional probability density of $y$ given parameters $\eta$ and state $i$.

Given a vector $\omega:= \{\omega_1,\dots,\omega_s\}$ of state probabilities, we put
$\theta:= (\eta,\omega)$.  The mixture density is then
$$
p(\theta;y) = \sum_{i=1}^s\omega_ip_i(\eta;y).
$$

Now suppose we are given a sequence $\{y_1,\dots,y_N\}$ of observations which we
assume are i.i.d. samples from this density,
and we want choose parameters $\theta$ to maximize the likelihood of the observations.
The likelihood function is  
\begin{equation*} \begin{split} 
L(\theta)
&:= \prod_{n=1}^N\sum_{i=1}^s\omega_ip_i(\eta,y_n) \\ 
&=
\sum_{i_1,\dots,i_N=1}^s\prod_{n=1}^N\omega_{i_n}p_{i_n}(\eta,y_n), \\ 
\end{split} 
\end{equation*} 
and the $Q$-function for this sum is 
$$
Q(\theta',\theta) = \sum_{i_1,\dots,i_N=1}^s\prod_{n=1}^N\omega'_{i_n}p_{i_n}(\eta';y_n)
\sum_{k=1}^N\log(\omega_{i_k}p_{i_k}(\eta;y_k)).
$$
The good news here is that there is a significant simplification of this expression.
Namely, the coefficient of $\log(\omega_mp_m(\eta;y_n))$ in the above sum is given by
\begin{align*}
\omega'_mp_m(\eta';y_n)\sum_{I:i_n = m}\prod_{j\neq n}\omega'_{i_j}p_{i_j}(\eta';y_j )
&=\omega'_mp_m(\eta';y_n)\prod_{j\neq n}\sum_{i=1}^s\omega'_ip_i(\eta';y_j)\\
&= \frac{\omega'_mp_m(\eta';y_n)}{p(\theta';y_n)}\prod_{j=1}^Np(\theta';y_j).
\end{align*}
Note that the quantity 
\begin{equation}\label{omega_mn}
\omega'_{mn} := \frac{\omega'_mp_m(\eta';y_n)}{p(\theta';y_n)}
\end{equation}
is the conditional probability of state $m$ at observation time $n$, given observation $y_n$ 
and parameters $\eta'$.
Thus, dividing by the constant $\prod_jp(\theta',y_j)$ and changing notation, the function to be
maximized is
\begin{equation}\label{Qfunc:0}
\tilde{Q}(\theta',\theta) := \sum_{m=1}^s\sum_{n=1}^N\omega'_{mn}\log(\omega_mp_m(\eta;y_n)),
\end{equation}
where, as above, $\omega'$ denotes the prior value, while $\omega$ and $\eta$ are the unknown parameters
to be solved for which will maximize $\tilde{Q}$.

\section{The Homogeneous Poisson Process}
For our purposes, a poisson process of rate $\lambda$ will be defined as an increasing sequence of random variables
$ \{T_0 < T_1 < T_2 < \dots < T_N\}$ defined on $(0,\infty)$ such that $\{\tau_i = T_i-T_{i-1}~|~ i = 1,2,\dots N\}$ are i.i.d.
exponential of rate $\lambda$. We often think of $T_i$ as the time of occurence of the $i^{th}$
event, where often the event is the arrival of something.  So in the following, we will call the $T_i$
``arrival times'' and the $\tau_i$ ``inter-arrival times''.  

The quantity of interest here is $Pd(T_n = t)$, the probability density that the $n^{th}$ arrival occurs at time $t$.
\begin{Thm}
  Let $\{0 < T_1<\dots<T_n<... \}$ be a Poisson process of rate $\lambda$.  Then
  \begin{equation}\label{gamma_dist}
  Pd(T_n = t) = \frac{\lambda^nt^{n-1}}{(n-1)!}e^{-\lambda{t}}.
  \end{equation}
  \begin{proof}
    Put $\tau_i = t_i - t_{i-1}$ for all $i$ as above. Then the $\tau_i$ are i.i.d. exponential of rate $\lambda$, and
    $t_j = \sum_{i=1}^j \tau_i$ for all $j$.  In particular $t_1 = \tau_1$ so the theorem is trivial for $n = 1$.
    Inductively, assume that it holds for $n-1$. Then $t = t_{n-1} + \tau_n$ is the sum of two independent random
    variables and hence $Pd(T_n = t)$ is the convolution
    \begin{align*}
      Pd(T_n = t) &= Pd(T_{n-1} = s)*({\lambda}e^{-\lambda(t-s)})\\
      &= \lambda\int_{s=0}^t\frac{\lambda^{n-1}s^{n-2}}{(n-2)!}e^{-\lambda{s}}{\lambda}e^{-\lambda(t-s)}ds \\
      &= \frac{\lambda^n}{(n-2)!)}e^{-\lambda{t}}\int_{s=0}^ts^{n-2}ds \\
      &= \frac{\lambda^nt^{n-1}}{(n-1)!}e^{-\lambda{t}}.
    \end{align*}
  \end{proof}
\end{Thm}
The probability density \eqref{gamma_dist} is known as the gamma density in the literature.

Now define $\eta(t)$ to be the ``counting function'' which is the total number of arrivals up to, and including, time $t$. $\eta(t)$
is an integer-valued random variable defined on $(0,\infty)$.
\begin{Cor}
  For a Poisson process of rate $\lambda$ as in the theorem, 
  \begin{equation}\label{poisson}
  Pr(\eta(t) = n) = \frac{\lambda^nt^{n}}{n!}e^{-\lambda{t}}.
  \end{equation}
  \begin{proof}
    For $n = 0$, the event $\eta(t) = 0$ is just the event $T_1 > t$, hence
    $$
    Pr(\eta(t) = 0) = \int_t^{\infty}Pd(T_1 = s)ds = \int_t^{\infty}{\lambda}e^-{\lambda{s}}ds = e^{-\lambda{t}}.
    $$
    Now for $n > 0$, we have
    \begin{align*}
      Pr(\eta(t) = n) &= \int_0^tPd(T_n = s ~\&~ \eta(t-s) = 0)ds\
      &= \int_0^t\frac{\lambda^ns^{n-1}}{(n-1)!}e^{-\lambda{s}}e^{-\lambda(t-s)}ds\\
      &=\frac{\lambda^n}{(n-1)!}e^{-\lambda{t}}\int_0^t s^{n-1}ds\\
      &= \frac{\lambda^nt^{n}}{n!}e^{-\lambda{t}}.
    \end{align*}
  \end{proof}
\end{Cor}
The probability distribution \eqref{poisson} is known in the literature as the poisson distribution.

\begin{Cor}
  For a Poisson process of rate $\lambda$ as in the theorem, 
  the expected number of arrivals up to time $t$ is $\lambda{t}$.
  \begin{proof}
    \begin{align*}
      \sum_{n=0}^{\infty}nPr(\eta(t) = n) &= \lambda{t}e^{-\lambda{t}}\sum_{n=1}^{\infty}\frac{(\lambda{t})^{n-1}}{(n-1)!}\\
      &=\lambda{t}e^{-\lambda{t}}e^{\lambda{t}}\\
      &= \lambda{t}.
    \end{align*}
  \end{proof}
\end{Cor}
        
   
\section{The Inhomogeneous Poisson Process}
We next consider a generalization of the Poisson process in which we allow the rate $\lambda$ to vary with time.
Among the infinitely many ways this might be done, we will consider here only a simple exponential decay model:
\begin{equation}\label{exp_rate}
  \lambda(t) := {\sigma}e^{-\rho{t}}
\end{equation}
where $\sigma$ and $\rho$ are non-negative decay parameters.
Then the expected number of arrivals in the interval $[t_0,t_1]$ is
\begin{equation}\label{k_hat}
  \hat{k}(t_0,t_1) := \int_{t_0}^{t_1}\lambda(t)dt = \frac{\sigma}{\rho}(e^{-\rho{t_0}}- e^{-\rho{t_1}}),
\end{equation}
and the mean rate in that interval is
\begin{equation}\label{lambda_hat}
  \hat{\lambda}(t_0,t_1) := \frac{\hat{k}(t_0,t_1)}{t_1 - t_0}.
\end{equation}

In the sequel, we will approximate an inhomogenous Poisson process with exponentially decaying rate $\lambda(t)$
in an interval $[t_0,t_1]$ by the homogeneous Poisson process with rate $\hat{\lambda}(t_0,t_1)$.  In particular,
\eqref{gamma_dist} becomes
\begin{equation}\label{gamma_dist:1}
  Pd(T_n = t) = \frac{\hat{\lambda}(0,t)^nt^{n-1}}{(n-1)!}e^{-t\hat{\lambda}(0,t)},
\end{equation}
and if $n$ is a random variable whose distribution is known but whose value is unknown, we will further approximate
\eqref{gamma_dist} by substituting $\hat{n}(0,t)$ for $n$ in \eqref{gamma_dist:1}.


\section{The Hawkes Process}
\subsection{A branching Poisson process}
We now introduce dependencies among the arrival times $T_i$, by allowing each arrival event 
to spawn a new Poisson process, which we call a child process as opposed to the original process which we
call the base process.  This leads to a view of the Hawkes process as a branching Poisson process. There
is another view of the Hawkes process as an inhomogeneous Poisson process whose intensity changes by positive
jumps at each arrival time.  The two views are mathematically equivalent, but we will take the branching view here.

An important difference between the base process and all the child processes is that the base process
has a constant rate $\lambda_0$ \footnote{This can be generalized to a time-dependent rate, but it is usually not exponentially decaying.} while the child processes all have exponentially decaying rates.  We denote the base
process by $\P_0$ and the child process spawned at arrival time
$t_j~(j > 0)$ by $\P_j$.  

We will make one further generalization, namely we may see
different types of events.  Event types are often called ``marks'' in the literature, and a process with different
event types is called a ``marked process''. 
Then our observations are pairs $(t,m)$ meaning that an event of type $m$ has occured at time $t$.  In this
case we denote the mark of event $i$ by $\mu(i)$ for $i > 0$, and we allow the exponential decay parameters for
child process
$\P_j$ to depend on $\mu(j)$, the mark of the originating event at arrival time $t_j$.  Then for
$j>0$, $\P_j$ has rate
\begin{equation}\label{child_rate}
\lambda_j(t) =
\begin{cases}
  \sigma_{m}e^{-\rho_{m}(t-t_j)}\quad\text{for $m = \mu(j)$ and $t > t_j$}\\
  0\quad\text{for $t \le t_j$}.
\end{cases}
\end{equation}
For $0 < j < i$, We define
\begin{align*}
  t_{ij} :&= t_i-t_j,\\
  \lambda_{ij} :&= \hat{\lambda}_j(0,t_{ij}) = \frac{\sigma_m}{\rho_mt_{ij}}(1-e^{-\rho_mt_{ij}}),\quad\text{and}\\
  \k_{ij} :&= \hat{\lambda_{ij}}t_{ij}.
\end{align*}

With these definitions, $\lambda_{ij}$ is the mean rate of process $\P_j$ over
the interval $[t_j,t_i]$, as given by \eqref{lambda_hat} and $\k_{ij}$ is the expected number
of arrivals from $\P_j$ up to time $t_i$.  In particular, we have
$\lambda_{i0} := \lambda_0$ and $\k_{i0} = \lambda_0t_{i0}$ for all $i$ because the base process is
homogeneous. 
  
\subsection{The Model}
We want to explain an observed arrival stream $\{(t_1,\mu(1)),\dots,(t_N,\mu(N))\}$ as the output
of a Hawkes process. Since the units of time are arbitrary, we will make the affine change of variable
$$
t' = \frac{t-t_0}{t_N-t_0},
$$
and change notation from $t'$ back to $t$.  In other words, we may assume without loss of generality that
$t_0 = 0$ and $t_N = 1$. Thus, $t_{i0}$ is just $t_i$, and $t_{N0} = t_N = 1$.  We will also assume that the
base process begins at $t_0 = 0$, so that $t_1$ is the arrival time of the first base process event, 

Suppose that $t_i$ is the arrival time of the $k_{ij}^{th}$ event generated by process $\P_j$ for some index $j < i$.
The we define

\begin{equation}\label{p_ij}
  p_{ij} :=  Pd(T_i = t_i \mid j, k_{ij}) = \frac{\lambda_{ij}^{k_{ij}}t_{ij}^{(k_{ij}-1)}}{(k_{ij}-1)!}e^{-\lambda_{ij}t_{ij}}
\end{equation}
by \eqref{gamma_dist}, where $\lambda_{ij}$ and $t_{ij}$ were defined above.

Unfortunately, however, the values of $k_{ij}$ and $\lambda_{ij}$ are not observed.  Indeed, we don't even
known the value of $j$. In other words, we don't know
which process $\P_j$ generated the event $T_i = t_i$, nor do we know how many events were generated by $\P_j$
prior to $t_i$.  Thus, we can't use \eqref{gamma_dist} directly. Instead,
we define a hidden state space $S := \{0,1,2,\dots,N\}$ and assume that $j\in{S}$ has probability $Pr(j) := \omega_j$.
This makes $j$ a random variable with a prior distribution and converts \eqref{p_ij} to a mixture distribution, but
we still don't know the values of $k_{ij}$ and $\lambda_{ij}$.  So we
will replace $k_{ij}$ by its expected value $\k_{ij}$, the expected number of events generated by $\P_j$
in the interval $(0,t_{ij}]$, which is  given by \eqref{k_hat}. We will also replace $\lambda_{ij}$ by its expected
  value $\k_{ij}t_{ij}^{-1}$.
Thus, making all these substitutions into \eqref{p_ij} we put
\begin{equation}\label{q_ij}
  \begin{split}
    q_{ij} := Pd(T_i = t_i \mid j) &= \frac{(\k_{ij}t_{ij}^{-1})^{\k_{ij}}t_{ij}^{(\k_{ij}-1)}}{\Gamma(\k_{ij})}e^{-\k_{ij}}\quad (j < i)\\
    &= \frac{\k_{ij}^{\k_{ij}}t_{ij}^{-1}}{\Gamma(\k_{ij})}e^{-\k_{ij}}.
  \end{split}
\end{equation}

Then our likelihood function becomes a product of mixture distributions, as discussed in section \eqref{MD}:

\begin{equation}\label{likelihood}
L = \prod_{i=1}^N\sum_{j=0}^{i-1}\omega_jq_{ij}.
\end{equation}

At first glance, it appears that we might have a large number of states.  However, note first that $q_{ij} = 0$ for $j \ge i$, and second that $q_{ij}$ decays exponentially in $t_i-t_j$, so in practice we can ignore states $j << i$.


\subsection{Optimizing the Parameters}
In this section we use the EM algorithm to optimize the model parameters.
Given the data $\{(t_1,\mu(t_i),\dots(t_N,\mu(t_N)\}$, we let $M$ denote the set of distinct marks $\mu(t_i)$
seen in the data.  Our model parameters are
$$
\theta := \lambda_0, \{\sigma_m, \rho_m, \mid m \in M\},~\text{and}~ \{\omega_j\mid 0\le j\le N\},
$$
and the Q-function to be maximized (see \eqref{Qfunc:0}) becomes
\begin{equation}\label{Q}
\tilde{Q}(\theta) = \sum_{i=1}^N\sum_{j=0}^{i-1}\omega_{ij}'\log(\omega_jq_{ij}),
\end{equation}
where, following \eqref{omega_mn}, $\omega'_{ij}$ is the (prior) conditional
probability of the event $T_i=t_i$,
given that it was generated by process $\P_j$.  We compute $\omega'_{ij}$ by
treating the density $\omega'_jq'_{ij}$ as the likelihood of the event $T_i = t_i$ given state $j$,
and normalizing to a distribution:
\begin{equation}\label{omega'_ij}
\omega'_{ij} :=
\begin{cases}
  \frac{\omega'_jq'_{ij}}{\sum_j\omega'_jq'_{ij}}&(j < i) \\
  0&(j \ge i).
\end{cases}
\end{equation}


We can now maximize $\tilde{Q}(\theta)$ by setting partial derivatives with respect to $\theta$ to
zero and solving the resulting equations for the posterior parameters.  We first solve for $\omega_j$, keeping in
mind the constraint
$$
\sum_{j=0}^{N-1}\omega_j = 1,
$$
which we will enforce using a Lagrange multiplier $\nu$ as follows:
For any $l \in [0,N-1]$ we have
$$
\frac{\partial\tilde{Q}}{\partial\omega_l} = \sum_{i=1}^N\frac{\omega'_{il}}{\omega_l},
$$
hence we solve
\begin{align*}
  0 &= \frac{\partial}{\partial\omega_l}\left(\tilde{Q} + \nu(1-\sum_{j=0}^{N-1}\omega_j )\right) \\
  &= \frac{1}\omega_l\sum_{i=1}^N\omega_{il}' - \nu.
\end{align*}
We conclude that
\begin{equation}\label{omega_j:0}
  \begin{split}
  \nu\omega_l &= \sum_{i=1}^N\omega_{il}',\quad\text{and summing over all l and interchanging the sums yields} \\
  \nu\sum_{l=0}^{N-1}\omega_l &= \sum_{i=1}^{N}\sum_{l=0}^{N-1}\omega'_{il}.
  \end{split}
\end{equation}
However, since by definition we have
$$
\sum_{l=0}^{N-1} \omega_l = 1 = \sum_{l=0}^{N-1}\omega'_{il}, 
$$
it follows that $\nu = N$ and thus \eqref{omega_j:0} yields
\begin{equation}\label{omega_j}
  \omega_j = \frac{1}{N}\sum_{i=1}^N\omega'_{ij}.
\end{equation}

To solve for the remaining parameters, we first expand \eqref{Q}:
\begin{equation}\label{Q1}
  \begin{split}
    \tilde{Q} &= \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}\log\left(\omega_j\frac{\k_{ij}^{\k_{ij}}t_{ij}^{-1}}
          {\Gamma(\k_{ij})}e^{-\k_{ij}} \right)\\
    &= \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}\left(\log(\omega_j)+\k_{ij}(\log(\k_{ij}) - \log(t_{ij})) 
          -\log(\Gamma(\k_{ij})) -\k_{ij}\right)\\
  \end{split}
\end{equation}
Note that \eqref{Q1} can be considerably simplified by using Stirling's approximation:
\begin{equation}\label{stirling}
  \log(\Gamma(x)) =  (x\log(x) -x - .5\log(x) + .5\log(2\pi) + O\left(\frac{1}{12(x+1)})\right).% + O\left(\frac{1}{12(x+1)(x+2)}.
\end{equation}
Substituting this approximation into \eqref{Q1} yields
\begin{equation}\label{Q2}
  \begin{split}
    \tilde{Q} &\approx \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}(\log(\omega_j)+\k_{ij}\log(\k_{ij}) - \log(t_{ij})
    -(\k_{ij}\log(\k_{ij}) -\k_{ij} -.5\log(\k_{ij}) \\
    &+ .5\log(2\pi)) -\k_{ij})\\
  &= \sum_{i=1}^N\sum_{j=0}^{i-1}\omega'_{ij}\left(\log(\omega_j) - \log(t_{ij}) + .5\log(\k_{ij})
  - .5\log(2\pi) \right),
  \end{split}
\end{equation}
and hence, using Stirling's approximation, we have 
\begin{equation}\label{dQ_dk}
  \frac{\partial\tilde{Q}}{\partial\k_{ij}} = \frac{\omega'_{ij}}{2\k_{ij}}\text{for $i > j$.}
\end{equation}
Of course, for $i \le j,~\k_{ij} = 0.$

For the sake of simplicity, we will now drop the dependence of $\sigma$ and $\rho$ on the mark $m$, which means
that all child processes have the same parameters.  So there are now three parameters $\lambda_0$, $\sigma$, and
$\rho$ which need to be re-estimated by choosing them to increase, if not maximize, $\tilde{Q}$.  
Using \eqref{Q2}, we see that each of these parameters only affect $\tilde{Q}$ indirectly, via $\k_{ij}$, and we recall
from \eqref{k_hat} that
$$
\k_{ij} = \begin{cases}
\lambda_0t_{i0} = \lambda_0t_i & \text{if $j = 0$}\\
\frac{\sigma}{\rho}(1-e^{-\rho{t_{ij}}}) & \text{if $0 < j < i$}\\
0 &\text{if $j\ge i$}.
\end{cases}
$$
Moreover, it is clear that for $\rho{t_{ij}}$ large,
$$
\k_{ij} \approx \frac{\sigma}{\rho},
$$
while by expanding the exponential in a Taylor series about 0, we see that
\begin{equation}\label{k_hat(0)}
\k_{ij}\mid_{\rho=0} := \lim_{\rho\rightarrow{0^+}}\k_{ij} = \sigma{t_{ij}}.
\end{equation}
In addition, \eqref{dQ_dk} implies that
\begin{equation}\label{dQ_dk(0)}
\left.\frac{\partial\tilde{Q}}{\partial\k_{ij}}\right|_{\rho=0} = \frac{\omega'_{ij}}{2\sigma t_{ij}}.
\end{equation}

Now taking partial derivatives of $\k_{ij}$ with respect to all three parameters, we have
\begin{equation}\label{dk_dparams}
  \begin{split}
    \frac{\partial\k_{i0}}{\partial\lambda_0} &= 
        t_{i0} \quad\text{for $j = 0$, and for $j > 0$ we have}\\
    \frac{\partial\k_{ij}}{\partial\sigma} &= 
      \frac{\k_{ij}}{\sigma}, \quad\text{and}\\
    \frac{\partial\k_{ij}}{\partial\rho} &= -\frac{\sigma}{\rho^2}(1-e^{-\rho t_{ij}}) + \frac{\sigma}{\rho}(t_{ij}e^{-\rho t_{ij}}) \\
    &= -\frac{\sigma}{\rho^2}\left(1-e^{-\rho{t_{tj}}} - \rho{t_{ij}}e^{-\rho{t_{ij}}}\right).\\
  \end{split}
\end{equation}
Moreover, to evaluate this last expression at $\rho = 0$, we expand the exponentials to the appropriate order:
\begin{equation}\label{dk_drho(0)}
  \begin{split}
    \left.\frac{\partial\k_{ij}}{\partial\rho}\right|_{\rho=0} &=
    -\frac{\sigma}{\rho^2}\left(\rho t_{ij} - \frac{1}{2}\rho^2t_{ij}^2 + O(\rho^3)) - \rho t_{ij}(1 - \rho t_{ij} + O(\rho^2)\right)\\
      &= -\frac{\sigma}{\rho^2}\left(\rho t_{ij} - \frac{1}{2}\rho^2t_{ij}^2 + O(\rho^3) - \rho t_{ij} + \rho^2 t_{ij}^2 + O(\rho^3)\right)\\
        &= -\frac{\sigma}{\rho^2}\left(\frac{1}{2}\rho^2t_{ij}^2 + O(\rho^3)\right)\\
          &= -\frac{1}{2}\sigma t_{ij}^2.
\end{split}
\end{equation}
Note that by definition,
$$
\sum_{j=0}^{N-1}\omega'_{ij} = 1\quad\text{for all } i,
$$
and therefore
\begin{equation}\label{W0+W1}
  W'_0 + W'_1 = N
\end{equation}

Next, we define
\begin{align*}
  W'_0 :&= \sum_{i=1}^N\omega'_{i0},\quad  W'_1 := \sum_{i>j>0}\omega'_{ij},\quad T_0 := \sum_{i=1}^Nt_i,\\
  T_1 :&= \sum_{i>j>0}t_{ij},\quad\text{and}\quad T_2 := \sum_{i>j>0}t_{ij}^2.
\end{align*}




Now for $j = 0$,  \eqref{dQ_dk} and \eqref{dk_dparams} immediately imply
\begin{equation}\label{dQ_dlambda}
\frac{\partial\tilde{Q}}{\partial\lambda_0} = \sum_{i=1}^N\frac{\omega'_{i0}}{2\k_{i0}}t_{i0} 
= \frac{1}{2\lambda_0}\sum_{i=1}^N\omega'_{i0} = \frac{W'_0}{2\lambda_0}.
\end{equation}
It's also easy to see that
\begin{equation}\label{dQ_dsigma}
  \frac{\partial\tilde{Q}}{\partial\sigma} = \sum_{i>j>0}\frac{\omega'_{ij}}{2\k_{ij}}\frac{\k_{ij}}{\sigma} 
= \frac{1}{2\sigma}\sum_{i>j>0}\omega'_{ij} = \frac{W'_1}{2\sigma}.
\end{equation}
And finally, the chain rule yields
\begin{equation}\label{dQ_drho}
\begin{split}
  \frac{\partial\tilde{Q}}{\partial\rho} &= \sum_{i>j>0}\frac{\partial\tilde{Q}}{\partial\k_{ij}}\cdot
  \frac{\partial\k_{ij}}{\partial\rho}\\
&= -\sum_{i>j>0}\frac{\omega'_{ij}}{2\k_{ij}}\frac{\sigma}{\rho}\left(\frac{1-e^{-\rho{t_{tj}}}}{\rho} - t_{ij}e^{-\rho{t_{ij}}}\right), \\
&= -\frac{1}{2}\sum_{i>j>0}\omega'_{ij}\left(\frac{1}{\rho} - t_{ij}\frac{e^{-\rho{t_{ij}}}}{1-e^{-\rho t_{ij}}}\right)\\
%&= -\frac{1}{2\rho}\sum_{i>j>0}\omega'_{ij}\left(\frac{1}{\rho} + t_{ij}\frac{1}{1-e^{\rho t_{ij}}}\right).
\end{split}
\end{equation}
Furthermore, using \eqref{dQ_dk(0)} and \eqref{dk_drho(0)}, we have
\begin{equation}\label{dQ_drho(0)}
  \left.\frac{\partial\tilde{Q}}{\partial\rho}\right|_{\rho=0} = -\sum_{i>j>0}\frac{\omega'_{ij}}{2\sigma t_{ij}}\frac{1}{2}\sigma t_{ij}^2 = -\frac{1}{4}\sum_{i>j>0}\omega'_{ij}t_{ij}.
\end{equation}
    
    

We can now solve for $\lambda_0$, $\sigma$, and $\rho$.  However, we
need to enforce an obvious constraint.  Namely,
for $i = 1,2,\dots,N$ the total number of expected arrivals at time $t_i$ is 
$$
\sum_{j<i}\k_{ij},
$$
while the actual number is of course $i$.  So we might want to enforce
the set of $N$ constraints
$$
\sum_{j < i}\k_{ij} - i = 0 \quad(1\le i\le N).
$$
However, this idea turns out to be unwieldly.  Instead, we sum over $i$, putting
\begin{equation}\label{constraint}
S := \sum_{i>j>0}\k_{ij} - N(N+1)/2,
\end{equation}
and maximize $\tilde{Q}$ subject to the single constraint $S = 0$.
Then using \eqref{dk_dparams} and \eqref{constraint} we get
\begin{equation} \label{dS_dparams}
  \begin{split}
    \frac{\partial{S}}{\partial\lambda_0} &= \sum_{i=1}^N\frac{\partial \k_{i0}}{\partial\lambda_0} = T_0,\\
    \frac{\partial{S}}{\partial\sigma} &= \frac{1}{\sigma}\sum_{i>j>0}\k_{ij} = \frac{1}{\sigma}(N(N+1)/2 - \lambda_0T_0),\\
    \frac{\partial{S}}{\partial\rho} &= -\frac{\sigma}{\rho^2}\sum_{i>j>0}\left(1-e^{-\rho t_{ij}}-\rho t_{ij}e^{-\rho t_{ij}}\right).
  \end{split}
\end{equation}
Moreover, \eqref{dk_drho(0)} implies that
\begin{equation}\label{dS_drho(0)}
  \left.\frac{\partial S}{\partial\rho}\right|_{\rho=0} = \sum_{i>j>0}\left.\frac{\partial\k_{ij}}{\partial\rho}\right|_{\rho=0}
  = -\frac{\sigma}{2}\sum_{i>j>0}t_{ij}^2 = -\frac{\sigma}{2}T_2.
\end{equation}


Now we solve the constrained maximization problem using a lagrange multiplier $\nu$ just as we did above.
Our first two constrained maximization equations are
\begin{equation}\label{eq1}
  \begin{split}
    0 &= \frac{\partial\tilde{Q}}{\partial\lambda_0} + \nu\frac{\partial{S}}{\partial\lambda_0} \\
    &=  \frac{W'_0}{2\lambda_0} + {\nu}T_0,\quad\text{whence}\\
    \lambda_0 &= -\frac{W'_0}{2\nu T_0}.
  \end{split}
\end{equation}
and
\begin{align*}
  0 &= \frac{\partial\tilde{Q}}{\partial\sigma} + \nu\frac{\partial{S}}{\partial\sigma} \\
  &= \frac{W'_1}{2\sigma} + \frac{\nu}{\sigma}(N(N+1)/2 - \lambda_0T_0),\quad\text{whence}\\
  \lambda_0 &= \frac{W_1'}{2\nu T_0} + \frac{N(N+1)}{2T_0}.
\end{align*}
Equating the two expressions above for $\lambda_0$, and using \eqref{W0+W1}, we have
\begin{equation}\label{eq2}
  \begin{split}
    -\frac{W_0'+W_1'}{2\nu T_0} &= \frac{N(N+1)}{2T_0} \\
    -\frac{W_0'+W_1'}{\nu} &= N(N+1), \\
    \nu = -\frac{1}{N+1}.
  \end{split}
\end{equation}

Then \eqref{eq1} simplifies to
\begin{equation} \label{lambda0:1}
    \lambda_0 = \frac{(N+1)W_0'}{2T_0}.
\end{equation}

Using \eqref{eq2}, \eqref{dQ_drho}, and \eqref{dS_dparams} our third and final constrained maximization
equation is
\begin{align*}
  0 &= f(\rho) := \frac{\partial\tilde{Q}}{\partial\rho} - \frac{1}{N+1}\frac{\partial{S}}{\partial\rho} \\
  &= -\frac{1}{2}\sum_{i>j>0}\omega'_{ij}\left(\frac{1}{\rho} - t_{ij}\frac{e^{-\rho{t_{ij}}}}{1-e^{-\rho t_{ij}}}\right)
  +\frac{\sigma}{(N+1)\rho^2}\sum_{i>j>0}\left(1 - e^{-\rho{t_{ij}}} - \rho t_{ij}e^{-\rho t_{ij}}\right).
\end{align*}
So we need to find the roots of $f(\rho)$.

Using the special values at $\rho=0$ found above at \eqref{dQ_drho(0)} and \eqref{dS_drho(0)}, we see that
$$
f(0) = -\frac{1}{4}\sum_{i>j>0}\omega'_{ij}t_{ij} +\frac{\sigma}{2(N+1)}T_2.
$$

Note that it is easy to solve \eqref{constraint} for $\sigma$ as a function of $\rho$ (and other
known quantities):
\begin{equation}\label{eq4}
  \sigma(\rho) = (N(N+1)/2 - \lambda_0T_0)\left(\sum_{i>j>0}\frac{1-e^{-\rho t_{ij}}}{\rho}\right)^{-1}.
\end{equation}
As noted above, the Taylor expansion for the exponential shows that
$$
\sigma(0) = (N(N+1)/2 - \lambda_0T_0)T_1^{-1}.
$$



%\section{Numerical Results}
\end{document}

